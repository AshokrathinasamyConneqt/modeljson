{
  "models": [
    {
      "name": "Gemma-3-270M-it-q8",
      "modelId": "litert-community/gemma-3-270m-it",
      "modelFile": "gemma3-270m-it-q8.task",
      "description": "Quantized (Q8) version of Gemma 3 270M Italian model, optimized for on-device inference via LiteRT.",
      "sizeInBytes": 318767104,
      "estimatedPeakMemoryInBytes": 600000000, 
      "version": "20250826",
      "llmSupportImage": false,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1,
        "maxTokens": 32768,
        "accelerators": "cpu,gpu"
      },
      "taskTypes": [
        "llm_chat",
        "llm_prompt_lab"
      ]
    }
  ]
}
